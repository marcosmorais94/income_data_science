1+2
knit_with_parameters("C:/FCD/Kaggle/Titanic/titanic_kaggle.RMD", encoding = "UTF-8")
library(rmarkdown)
library(Amelia)
A = c(10,20,20,30,40)
B = c(30,NULL,40,50,60)
C = c(15,10,30,40,NULL)
D = c(13,12,NULL,NULL,NULL)
E = c(NULL,NULL,NULL,NULL,NULL)
dataset = data.frame(A,B, C, D, E)
missmap(dataset)
dataset = data.frame(A,B,C,D,E)
A = c(10,20,20,30,40)
B = c(30,NA,40,50,60)
C = c(15,10,30,40,NA)
D = c(13,12,NA,NA,NA)
E = c(NA,NA,NA,NA,NA)
dataset = data.frame(A,B,C,D,E)
missmap(dataset)
library(Amelia)
A = c(10,20,20,30,40)
B = c(30,NA,40,50,60)
C = c(15,10,30,40,NA)
D = c(13,12,NA,NA,NA)
E = c(NA,NA,NA,NA,NA)
dataset = data.frame(A,B,C,D,E)
missmap(dataset)
exp(0.13)
round(exp(0.13),2)
exp(0.8)
round(exp(0.8).2)
round(exp(0.8),2)
round(exp(0.8),2) - 1
(round(exp(0.8),2) - 1)*100
(round(exp(0.02),2) - 1)*100
(round(exp(-0.67),2) - 1)*100
?glm
install.packages('DAAG')
install.packages('party')
install.packages('rpart')
install.packages('rpart.plot')
install.packages('mlbench')
install.packages('pROC')
install.packages('tree')
?rpart
rpart?
library(rpart)
?rpart
library(rpart)
# Aplicando o Prune
?prune
?rpart
3487-2353
3787-2052
4165-1847
3372-2920
# Definindo diretório ####
setwd('C:/FCD/R/UCI/Income_Predict')
getwd()
# Carga dos pacotes ####
library(ggplot2)
library(dplyr)
library(caret)
library(RColorBrewer)
library(forcats)
library(ROCR)
library(e1071)
# Carga do dataset balanceado
df_modelo <- read.csv('df_final.csv') #32.561 registros
# Dataset está balanceado
round(prop.table(table(df_final$income))*100,2)
# Dataset está balanceado
round(prop.table(table(df_modelo$income))*100,2)
# Dataset está balanceado
View(df_modelo)
bd1 <- read.csv('adult_train.csv') #32.561 registros
bd2 <- read.csv('adult_test.csv') # 16.281 registros
bd <- rbind(bd1, bd2) #48.842 registros
rm(bd1, bd2)
# Pré - Processamento ####
bd_modelo <- bd
# Remoção variável com mais registros inválidos
bd_modelo <- bd_modelo[bd_modelo$occupation != ' ?',]
# Label da variável target
bd_modelo['income'] <- case_when(bd_modelo$income == '<=50K' ~ 0,
bd_modelo$income == '>50K' ~ 1,
TRUE ~ 0)
bd1 <- read.csv('adult_train.csv') #32.561 registros
bd2 <- read.csv('adult_test.csv') # 16.281 registros
bd <- rbind(bd1, bd2) #48.842 registros
rm(bd1, bd2)
bd$income <- case_when(bd$income == ' <=50K' ~ '<=50K',
bd$income == ' >50K' ~ '>50K',
bd$income == ' <=50K.' ~ '<=50K',
bd$income == ' >50K.' ~ '>50K',
TRUE ~ 'NA')
# Pré - Processamento ####
bd_modelo <- bd
# Remoção variável com mais registros inválidos
bd_modelo <- bd_modelo[bd_modelo$occupation != ' ?',]
bd_modelo['income'] <- case_when(bd_modelo$income == '<=50K' ~ 0,
bd_modelo$income == '>50K' ~ 1,
TRUE ~ 0)
str(bd_modelo)
# Remoção variável education.num
#Já existe uma variável que trata da escolaridade dos participantes da pesquisa
bd_modelo['education.num'] <- NULL
bd_dmy <- bd_modelo[,-15]
dmy <- dummyVars(" ~ .", data = bd_dmy, fullRank = T)
dat_modelo <- data.frame(predict(dmy, newdata = bd_dmy))
bd_final <- dat_modelo
bd_final['income'] <- bd_modelo[,14]
nomes <- colnames(bd_final)
# Carga do dataset balanceado
df_modelo <- read.csv('df_final.csv') #69.222 registros
# Dataset está balanceado
colnames(df_modelo) <- nomes
View(df_modelo)
round(prop.table(table(df_modelo$income))*100,2)
# Definindo diretório ####
setwd('C:/FCD/R/UCI/Income_Predict')
getwd()
# Introdução ####
# O dataset foi feito a partir de uma pesquisa nacional em 1994 nos E.U.A
# O objetivo da análise é prever quem pode ter uma renda > ou <= $50K
# Essa análise tem como objetivo retornar uma acurácia de 90%
# Dicionário de Dados
# fonte: https://archive.ics.uci.edu/ml/datasets/adult
# Carga dos datasets ####
bd1 <- read.csv('adult_train.csv') #32.561 registros
bd2 <- read.csv('adult_test.csv') # 16.281 registros
bd <- rbind(bd1, bd2) #48.842 registros
rm(bd1, bd2)
View(bd)
# Carga dos pacotes ####
library(ggplot2)
library(dplyr)
library(caret)
library(RColorBrewer)
library(forcats)
library(ROCR)
library(e1071)
# Analise Exploratória ####
#Tipos de dados
str(bd)
summary(bd)
# Variável Preditora
bd$income <- case_when(bd$income == ' <=50K' ~ '<=50K',
bd$income == ' >50K' ~ '>50K',
bd$income == ' <=50K.' ~ '<=50K',
bd$income == ' >50K.' ~ '>50K',
TRUE ~ 'NA')
# Gráficos
# Histograma
hist <- ggplot(bd, aes(x = age)) +
geom_histogram(color = 'white', fill = 'aquamarine4', binwidth = 2) +
theme(panel.background = element_blank()) +
labs(title = 'Histograma Idade',
x = 'Idade',
y = 'Contagem') +
scale_x_continuous(breaks = c(seq(from = min(bd$age),
to = max(bd$age),
by = 5)),
limits = c(15, 80))
hist
# Pelo histograma vemos que claramente os dados não estão normalizados
# Nesse caso, as variáveis numéricas precisam ser normalizadas.
# Como temos mais de uma, a técnica deve ser aplicada para todas.
# Análise Escolaridade
colunas <- ggplot(bd) +
geom_bar(aes(x = fct_infreq(education),
fill = income)) +
labs(x = element_blank(),
y = 'Quantidade',
title = ' Variável Income x Escolaridade') +
theme(panel.background = element_blank(),
legend.title = element_text('Income'))
colunas + scale_fill_manual(values = c('azure4', 'aquamarine4'))
# Vemos que High School é a principal categoria
# O nível da escolaridade pode sim influenciar a renda, a maioria das pessoas om doutorado ganham mais de 50K
# Análise raça
colunas_raca <- ggplot(bd) +
geom_bar(aes(x = fct_infreq(race),
fill = income)) +
labs(x = element_blank(),
y = 'Quantidade',
title = ' Variável Income x Raça') +
theme(panel.background = element_blank())
colunas_raca + scale_fill_manual(values = c('deepskyblue', 'cyan4'))
# Outro ponto que chama atenção é a raça, onde brancos tendem a ganhar mais que as outras raças
# Análise sexo
colunas_sexo <- ggplot(bd) +
geom_bar(aes(x = fct_infreq(sex),
fill = income)) +
labs(x = element_blank(),
y = 'Quantidade',
title = ' Variável Income x Raça') +
theme(panel.background = element_blank())
colunas_sexo + scale_fill_manual(values = c('deepskyblue', 'cyan4'))
# Homens tendem a ter uma renda maior que mulheres.
# As 3 variáveis analisadas tendem a ter uma importância considerável para o modelo.
# Classes variável target
round(prop.table(table(bd$income))*100,2)
# O dataset possui 76% com pessoas ganhando menos de 50K
# Temos 16% de pessoas ganhando mais de 50K
# O dataset, apesar de estar desbalanceado, possui um comportamento esperado.
# Valores NAs
sum(is.na(bd))
# Não existe valores NA, ou não classificados dessa maneira.
# Vale a pena analisar se existe valores diferentes nos atributos, como caracteres especipais como !
sapply(X = bd, FUN = 'unique')
#workclass, occupation e native country possuem valores como ?
sum(ifelse(bd$workclass == ' ?', 1, 0)) #2.799 registros
sum(ifelse(bd$occupation == ' ?', 1, 0)) #2.809 registros
sum(ifelse(bd$native.country == ' ?', 1, 0)) #857 registros
round((sum(ifelse(bd$occupation == ' ?', 1, 0))/nrow(bd))*100,2)
# 5,75% dos dados estão com ? em occupation.
# A decisão será melhor remover esses dados no pré-processamento
# Pré - Processamento ####
bd_modelo <- bd
# Remoção variável com mais registros inválidos
bd_modelo <- bd_modelo[bd_modelo$occupation != ' ?',]
# Label da variável target
bd_modelo['income'] <- case_when(bd_modelo$income == '<=50K' ~ 0,
bd_modelo$income == '>50K' ~ 1,
TRUE ~ 0)
# Remoção variável education.num
#Já existe uma variável que trata da escolaridade dos participantes da pesquisa
bd_modelo['education.num'] <- NULL
str(bd_modelo)
# Criação de variáveis dummy
bd_dmy <- bd_modelo[,-15]
dmy <- dummyVars(" ~ .", data = bd_dmy, fullRank = T)
dat_modelo <- data.frame(predict(dmy, newdata = bd_dmy))
View(dat_modelo)
bd_final <- dat_modelo
bd_final['income'] <- bd_modelo[,14]
#Usar csv para balancear classes com Python
# Motivos de muitos bugs com SMOTE em R
write.csv2(bd_final, 'BD_modelo.csv', row.names = FALSE)
nomes <- colnames(bd_final)
# https://www.pluralsight.com/guides/encoding-data-with-r
# Carga do dataset balanceado
df_modelo <- read.csv('df_final.csv') #69.222 registros
# Dataset está balanceado
colnames(df_modelo) <- nomes
View(df_modelo)
str(df_modelo)
round(prop.table(table(df_modelo$income))*100,2)
#round(prop.table(table(df_treino$income))*100,2)
prop.table(table(df_treino$income))
prop.table(table(df_modelo$income))
table(df_modelo$income)
View(df_modelo)
# Carga do dataset balanceado
df_modelo <- read.csv('df_final.csv') #69.222 registros
nomes <- colnames(bd_final)
# Carga do dataset balanceado
df_modelo <- read.csv('df_final.csv') #69.222 registros
colnames(df_modelo) <- nomes
table(df_modelo$income)
bd_final[c('age','fnlwgt','capital.gain','capital.loss','hours.per.week')] <-
scale(
bd_final[c('age','fnlwgt','capital.gain','capital.loss','hours.per.week')])
# Função para normalização dos dados
df_modelo[c('age','fnlwgt','capital.gain','capital.loss','hours.per.week')] <-
scale(
df_modelo[c('age','fnlwgt','capital.gain','capital.loss','hours.per.week')])
amostra_dados <- sample(x = nrow(df_modelo),
size = 0.8 * nrow(df_modelo),
replace = FALSE)
# Dados de treino e teste
bd_treino <- bd_final[amostra_dados,]
bd_teste <- bd_final[-amostra_dados,]
# Gráfico Antes do Balanceamento
colunas_income <- ggplot(bd_treino) +
geom_bar(aes(x = income)) +
labs(x = 'Classe Income',
y = 'Quantidade',
title = 'Análise Variável Income') +
theme(panel.background = element_blank())
# Modelo v1.0 - Regressão Logística
modelo_v1 <- glm(formula = income ~ ., data = df_treino, family = 'binomial')
# Modelo v1.0 - Regressão Logística
modelo_v1 <- glm(formula = income ~ ., data = bd_treino, family = 'binomial')
bd_teste_ml <- bd_teste[,-97]
resultado_v1 <- predict(modelo_v1, newdata = bd_teste_ml, type = 'response')
View(resultado_v1)
#Variável resposta com valores convertidos em binário
resultado_v1 <- ifelse(resultado_modelo > 0.5, 1, 0)
#Variável resposta com valores convertidos em binário
resultado_v1 <- ifelse(resultado_v1 > 0.5, 1, 0)
resultado_v1
confusionMatrix(table(data = resultado_v1, reference = bd_teste$income))
# Feature Selection
formula <- "income ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = df_treino, method = "glm", trControl = control)
model <- train(formula, data = bd_treino, method = "glm", trControl = control)
sum(is.na(df_treino))
sum(is.na(bd_treino))
sapply(X = bd_treino, FUN = 'is.na')
View(bd_treino)
View(bd_final)
# Dados de treino e teste
bd_treino <- df_modelo[amostra_dados,]
bd_teste <- df_modelo[-amostra_dados,]
View(bd_treino)
# Remove a varíavel target para teste do modelo
bd_teste_ml <- bd_teste[,-97] #Usar para teste do modelo!
# Modelo v1.0 - Regressão Logística
modelo_v1 <- glm(formula = income ~ ., data = bd_treino, family = 'binomial')
# Cálculo das probilidades de regressão
resultado_v1 <- predict(modelo_v1, newdata = bd_teste_ml, type = 'response')
#Variável resposta com valores convertidos em binário
resultado_v1 <- ifelse(resultado_v1 > 0.5, 1, 0)
confusionMatrix(table(data = resultado_v1, reference = bd_teste$income))
summary(modelo_v1)
confusionMatrix(table(data = resultado_v1, reference = bd_teste$income))
# Feature Selection
formula <- "income ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = bd_treino, method = "glm", trControl = control)
importance <- varImp(model, scale = FALSE)
# Plot
plot(importance)
# Plot
importance$importance
# Plot
A <- importance$importance %>% arrange(desc(Overall)) %>% top_n(20)
plot(A)
A
barplot(A)
str(A)
# Plot
A <- importance$importance %>% arrange(desc(Overall)) %>% top_n(30)
A
nam <- names(A)
nam
importance$calledFrom
importance$importance
str(importance$importance)
